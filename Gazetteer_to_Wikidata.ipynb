{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80530900",
   "metadata": {},
   "source": [
    "## Workflow for matching and importing location data from iDAI.gazetteer to Wikidata\n",
    "\n",
    "This notebook describes the workflow used in FAIR.rdm for matching location data in iDAI.gazetteer with Wikidata.\n",
    "\n",
    "The Python code supports the creation of new locations using quick statements.\n",
    "\n",
    "---\n",
    "\n",
    "### Workflow zum Abgleich und Import von Ortsdaten aus iDAI.gazetteer zu Wikidata\n",
    "\n",
    "Das Notebook beschreibt den in FAIR.rdm praktizierten Workflow zum Abgleich von Ortsdaten im iDAI.gazetteer mit Wikidata.\n",
    "\n",
    "Der Python-Code unterstützt beim Anlegen neuer Orte mittels Quick Statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eb2e5c",
   "metadata": {},
   "source": [
    "First, [OpenRefine](https://openrefine.org/) must be used to compare which data is already in Wikidata. The Wikidata URIs must then be specified in a separate column (Compare/Add columns with URLs of matched entities).\n",
    "\n",
    "This table can then be exported for the following code.\n",
    "\n",
    "Further information: https://www.wikidata.org/wiki/Wikidata:Tools/OpenRefine\n",
    "\n",
    "---\n",
    "\n",
    "Als erstes muss mit [OpenRefine](https://openrefine.org/) ein Agleich durchgeführt werden, welche Daten sich bereits in Wikidata befinden. Die Wikidata URIs sind dann in einer separaten Spalten anzugeben (Abgleichen/Add columns with URLs of matched entities).\n",
    "\n",
    "Diese Tablle kann dann für den folgenden Code exportiert werden.\n",
    "\n",
    "Weitere Informationen: https://www.wikidata.org/wiki/Wikidata:Tools/OpenRefine/de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f685858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toimport = pd.read_excel(\"Gazetteer_To_Wikidata_Mapping_2025-07-11.xlsx\", sheet_name=\"wikidata\")\n",
    "df_toimport = df_toimport.fillna(\"absent\")\n",
    "\n",
    "df_toimport = df_toimport[df_toimport['Wikidata_URL'] == \"absent\"]\n",
    "df_toimport = df_toimport.reset_index(drop=True)\n",
    "df_toimport.drop('Wikidata_URL', axis=1, inplace=True)\n",
    "\n",
    "#Test with a subset of the data:\n",
    "#df_test = df_toimport[14:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb588db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the first column contains Gazetteer URIs, the Gazetteer ID is extracted here.\n",
    "def get_gaz_id(uri):\n",
    "    parts = uri.split(\"/\")\n",
    "    gazid = parts[-1]\n",
    "    return gazid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5befc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function retrieves the name of a place from the Gazetteer.\n",
    "def get_gaz_title(gaz_id):\n",
    "    gaz_id = gaz_id.split(\"/\")[-1]\n",
    "    url = f\"https://gazetteer.dainst.org/doc/{gaz_id}.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'prefName' in data:\n",
    "            title = data['prefName']['title']\n",
    "            return title\n",
    "        else:\n",
    "            title = \"ERROR_no_title!!!\"\n",
    "            return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff854c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes the name of a place and sets it as the Wikidata label.\n",
    "def get_label(row):\n",
    "    label = row['PlaceName']\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aadd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function retrieves the type of a place from the Gazetteer and sets it as the Wikidata description. It may needs to be extended.\n",
    "\n",
    "def get_gaz_type(gaz_id):\n",
    "    url = f\"https://gazetteer.dainst.org/doc/{gaz_id}.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        types = data['types']\n",
    "        title = data['prefName']['title']\n",
    "        if \"Keramik\" in title:\n",
    "            type = \"archäologischer Keramikstil\"\n",
    "        elif 'archaeological-area' in types:\n",
    "            type = \"Archäologischer Bereich\"\n",
    "        elif 'archaeological-site' in types:\n",
    "            type = \"Archäologischer Ort\"\n",
    "        else:\n",
    "            type = types[0]\n",
    "        return type\n",
    "    else:\n",
    "        type = \"ERROR_no_type!!!\"\n",
    "        return type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc7053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function determines the statement \"is a ...\" (P31) for Wikidata.\n",
    "\n",
    "def get_p31(description):\n",
    "    if description == \"Archäologischer Bereich\":\n",
    "        p31 = \"Q839954 (Archäologische Stätte)\"\n",
    "        return p31\n",
    "    elif description == \"archäologischer Keramikstil\":\n",
    "        p31 = \"Q24017852 (Keramikstil)\"\n",
    "        return p31\n",
    "    elif description == \"Archäologischer Ort\":\n",
    "        p31 = \"Q839954 (Archäologische Stätte)\"\n",
    "        return p31\n",
    "    else:\n",
    "        p31 = \"set manually\"\n",
    "        return p31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the coordinates are polygons, this function calculates the centroid of the polygon and imports it into Wikidata.\n",
    "\n",
    "def polygon_centroid(coords):\n",
    "    # Unwrap the nested list structure\n",
    "    points = coords[0][0]\n",
    "    x_list = [p[0] for p in points]\n",
    "    y_list = [p[1] for p in points]\n",
    "    n = len(points) - 1  # last point is same as first\n",
    "\n",
    "    area = 0.0\n",
    "    cx = 0.0\n",
    "    cy = 0.0\n",
    "\n",
    "    for i in range(n):\n",
    "        factor = (x_list[i] * y_list[i+1] - x_list[i+1] * y_list[i])\n",
    "        area += factor\n",
    "        cx += (x_list[i] + x_list[i+1]) * factor\n",
    "        cy += (y_list[i] + y_list[i+1]) * factor\n",
    "\n",
    "    area *= 0.5\n",
    "    if area == 0:\n",
    "        # fallback: average of points\n",
    "        return (sum(x_list)/len(x_list), sum(y_list)/len(y_list))\n",
    "    cx /= (6.0 * area)\n",
    "    cy /= (6.0 * area)\n",
    "    return (cx, cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function retrieves the latitude of a place from the Gazetteer.\n",
    "\n",
    "def get_latitude(gaz_id):\n",
    "    url = f\"https://gazetteer.dainst.org/doc/{gaz_id}.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "        location = data['prefLocation']\n",
    "        if 'coordinates' in location:\n",
    "            lat = data['prefLocation'][\"coordinates\"][0]\n",
    "        elif 'shape' in location:\n",
    "            coords = location['shape']\n",
    "            center = polygon_centroid(coords)\n",
    "            lat = center[0]\n",
    "        else:\n",
    "            lat = \"ERROR_no_coordinates!!!\"\n",
    "        return lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba080447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function retrieves the longitude of a place from the Gazetteer.\n",
    "\n",
    "def get_longitude(gaz_id):\n",
    "    url = f\"https://gazetteer.dainst.org/doc/{gaz_id}.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'prefLocation' in data and 'coordinates' in data['prefLocation']:\n",
    "            long = data['prefLocation'][\"coordinates\"][-1]\n",
    "        elif 'shape' in data['prefLocation']:\n",
    "            coords = data['prefLocation']['shape']\n",
    "            center = polygon_centroid(coords)\n",
    "            long = center[1]\n",
    "        else:\n",
    "            long = \"ERROR_no_coordinates!!!\"\n",
    "        return long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function determines the country of a place based on its latitude and longitude using the Nominatim service from OpenStreetMap.\n",
    "\n",
    "def get_country_from_latlon(lat, lon):\n",
    "    url = \"https://nominatim.openstreetmap.org/reverse\"\n",
    "    params = {\n",
    "        \"lat\": lon,\n",
    "        \"lon\": lat,\n",
    "        \"format\": \"json\",\n",
    "        \"zoom\": 3,  # 3 = country level\n",
    "        \"addressdetails\": 1\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; CopilotBot/1.0)\"\n",
    "    }\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        address = data.get(\"address\", {})\n",
    "        country = address.get(\"country\")\n",
    "        return country\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db689884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Loop\n",
    "\n",
    "labels = []\n",
    "descriptions = []\n",
    "type = []\n",
    "lat = []\n",
    "long = []\n",
    "states = []\n",
    "\n",
    "for index, row in df_toimport.iterrows():\n",
    "    label = get_label(row)\n",
    "    labels.append(label)\n",
    "    gaz_id = get_gaz_id(row['GazetteerID'])\n",
    "    description = get_gaz_type(gaz_id)\n",
    "    descriptions.append(description)\n",
    "    p31_value = get_p31(description)\n",
    "    type.append(p31_value)\n",
    "    latitude = get_latitude(gaz_id)\n",
    "    longitude = get_longitude(gaz_id)\n",
    "    #latitude and longitude should only have five decimal places\n",
    "    latitude = round(latitude, 5)\n",
    "    longitude = round(longitude, 5)\n",
    "    lat.append(latitude)\n",
    "    long.append(longitude)\n",
    "    country = get_country_from_latlon(latitude, longitude)\n",
    "    states.append(country)\n",
    "    #Wait for three seconds to avoid rate limiting\n",
    "    time.sleep(3)\n",
    "\n",
    "print(labels)\n",
    "print(descriptions)\n",
    "print(type)\n",
    "print(lat)\n",
    "print(long)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "df_toexport = pd.DataFrame({\n",
    "    'GazetteerID': df_toimport['GazetteerID'],\n",
    "    'Label': labels,\n",
    "    'Description': descriptions,\n",
    "    'Type': type,\n",
    "    'Latitude': lat,\n",
    "    'Longitude': long,\n",
    "    'Country': states\n",
    "})\n",
    "\n",
    "df_toexport.to_csv(\"Wikidata_information.csv\", index=False, encoding='utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10abaf1",
   "metadata": {},
   "source": [
    "Now you can make the necessary changes to the CSV file and add entries manually.\n",
    "\n",
    "Then you can generate the QuickStatements using the following code:\n",
    "\n",
    "---\n",
    "\n",
    "Jetzt können an der CSV nötige Änderungen vorgenommen werden und Einträge manuell ergänzt werden.\n",
    "\n",
    "Dananch können mit folgendem Code die QuickStatements erzeugt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The mapping of countries to Wikidata Q-IDs may need to be extended.\n",
    "\n",
    "country_mapping = {\n",
    "    \"ليبيا\": \"Q1016\",   # Libyen\n",
    "    \"Sudan\": \"Q1049\",\n",
    "    \"مصر\": \"Q79\",       # Ägypten\n",
    "    \"Niger\": \"Q1032\",\n",
    "    \"Mali\": \"Q912\",\n",
    "    \"Algérie ⵍⵣⵣⴰⵢⴻⵔ الجزائر\": \"Q262\",\n",
    "    \"République démocratique du Congo\": \"Q974\",\n",
    "    \"Congo\": \"Q971\",\n",
    "    \"Cameroun\": \"Q1009\",\n",
    "    \"السودان\":\"Q1049\" #Sudan\n",
    "}\n",
    "\n",
    "df = pd.read_csv('Wikidata_information.csv', sep=\";\")\n",
    "\n",
    "qs_lines = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    label = str(row[\"Label\"]).strip()\n",
    "    desc_de = str(row[\"Description\"]).strip()\n",
    "    desc_en = \"archaeological site\"\n",
    "    type_qid = row[\"Type\"].split()[0].strip()\n",
    "    lat = row[\"Latitude\"]\n",
    "    lon = row[\"Longitude\"]\n",
    "    country = country_mapping.get(str(row[\"Country\"]).strip(), None)\n",
    "    #country = row[\"Country\"]\n",
    "    gazetteer_url = row[\"GazetteerID\"]\n",
    "\n",
    "    qs_lines.append(\"CREATE\")\n",
    "    qs_lines.append(f'LAST|Lde|\"{label}\"')\n",
    "    qs_lines.append(f'LAST|Den|\"{desc_en}\"')\n",
    "    qs_lines.append(f'LAST|Dde|\"{desc_de}\"')\n",
    "    qs_lines.append(f'LAST|P31|{type_qid}')\n",
    "    qs_lines.append(f'LAST|P625|@{lon}/{lat}|S854|\"{gazetteer_url}\"')\n",
    "    if country:\n",
    "        qs_lines.append(f'LAST|P17|{country}')\n",
    "\n",
    "    qs_lines.append(\"\")\n",
    "\n",
    "# Save file\n",
    "with open('quickstatements_ortsimport.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(qs_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3602d34d",
   "metadata": {},
   "source": [
    "Go to https://quickstatements.toolforge.org/\n",
    "\n",
    "Log in with your Wikidata account.\n",
    "\n",
    "Click on “New batch.”\n",
    "\n",
    "If a message appears stating that the current wiki account does not have “autoconfirmed” status, 50 changes must be made manually in Wikidata. The account will then be automatically activated.\n",
    "\n",
    "Paste the contents of the file or upload it.\n",
    "\n",
    "Click on “Run” or “Only add” (for testing).\n",
    "\n",
    "---\n",
    "\n",
    "Gehe zu https://quickstatements.toolforge.org/\n",
    "\n",
    "Melde dich mit deinem Wikidata-Account an.\n",
    "\n",
    "Klicke auf „New batch“.\n",
    "\n",
    "Wenn hier eine Meldung angezeigt wird, dass das aktuelle Wiki-Konto nicht den Status \"autoconfirmed\" hat, müssen noch manuell 50 Änderungen in Wikidata durchgeführt werden. Dann wird das Konto automatisch freigeschaltet.\n",
    "\n",
    "Füge den Inhalt der Datei ein oder lade sie hoch.\n",
    "\n",
    "Klicke auf „Run“ oder „Only add“ (zum Testen)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f2fb7",
   "metadata": {},
   "source": [
    "Developed by Lukas Lammers in the FAIR.rdm project, part of the DFG-funded SPP 2143 “Entangled Africa.”\n",
    "\n",
    "With support from GitHub Copilot (AI assistant) for code development and optimization.\n",
    "\n",
    "Version 1.0, July 15, 2025\n",
    "\n",
    "---\n",
    "\n",
    "Entwickelt von Lukas Lammers im Projekt FAIR.rdm, teil des DFG-geförderten SPP 2143 \"Entangled Africa\".\n",
    "\n",
    "Mit Unterstützung von GitHub Copilot (KI-Assistent) bei der Code-Entwicklung und -Optimierung.\n",
    "\n",
    "Version 1.0, 15.07.2025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
