{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6bd0078",
   "metadata": {},
   "source": [
    "## Skript zum Harvesten von Ortsdaten aus iDAI.chronontology\n",
    "\n",
    "Mithlife dieses einfachen Skripts lassen sich Ortszuweisungen in Chronontology extrahieren.\n",
    "\n",
    "Eingelesen wird ein Auszug der Chronontology Konkordanz.\n",
    "\n",
    "Ausgegeben wird eine Liste aller Ortsnamen und IDs im iDAI.gazetteer, die mit den eingegebenen Perioden primär assoziiert sind. Dies bedeutet, dass Kerngebeite gegenüber Regionen bevorzugt werden, und Regionen wiederrum über namensgebende Orte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f685858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Einlesen der Konkordanz\n",
    "\n",
    "#Choose CSV or Excel file\n",
    "#df_konkordanz = pd.read_excel(\"konkordanz_20240527.xlsx\", sheet_name=\"nur SPP\")\n",
    "df_konkordanz = pd.read_csv(\"konkordanz_nurSPP.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "print(df_konkordanz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d8de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liste aller eingegebenen ChronoIDs\n",
    "\n",
    "chronoids = df_konkordanz[\"chronontologyID\"]\n",
    "chronoids = chronoids.tolist()\n",
    "\n",
    "#print(chronoids)\n",
    "\n",
    "#Testweise nur die ersten 10 ChronoIDs verwenden:\n",
    "#chronoids_test = chronoids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve Title, Core Area or SpatiallPartOf from Chronontology API\n",
    "\n",
    "url = \"https://chronontology.dainst.org/data/period/\"\n",
    "\n",
    "#Funktion zur Abfrage des Namens einer Periode\n",
    "def get_chrono_name(chrono_id):\n",
    "    response = requests.get(f\"{url}{chrono_id}\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        #print(data)\n",
    "        title = data['resource']['names']\n",
    "        #get the first value\n",
    "        title = title.values()\n",
    "        title = list(title)[0][0]\n",
    "        #print(title)\n",
    "        return title\n",
    "    else:\n",
    "        title = \"ERROR\"\n",
    "        return title\n",
    "\n",
    "#Funktion zur Abfrage des Kerngebietes einer Periode\n",
    "def get_chrono_core_area(chrono_id):\n",
    "    response = requests.get(f\"{url}{chrono_id}\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        #print(data['resource'])\n",
    "        if 'hasCoreArea' in data['resource']:\n",
    "            core_area = data['resource']['hasCoreArea'][0]\n",
    "            return core_area\n",
    "        else:\n",
    "            core_area = \"no_core_area\"\n",
    "            return core_area\n",
    "    else:\n",
    "        core_area = \"ERROR\"\n",
    "        return core_area\n",
    "\n",
    "#Funktion zur Abfrage der Region einer Periode\n",
    "def get_chrono_region(chrono_id):\n",
    "    response = requests.get(f\"{url}{chrono_id}\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        #print(data['resource'])\n",
    "        if 'spatiallyPartOfRegion' in data['resource']:\n",
    "            region = data['resource']['spatiallyPartOfRegion'][0]\n",
    "            return region\n",
    "        else:\n",
    "            region = \"no_region\"\n",
    "            return region\n",
    "    else:\n",
    "        region = \"ERROR\"\n",
    "        return region\n",
    "\n",
    "#Funktion zur Abfrage des namensgebenden Ortes einer Periode\n",
    "def get_chrono_named_after(chrono_id):\n",
    "    response = requests.get(f\"{url}{chrono_id}\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        #print(data['resource'])\n",
    "        if 'isNamedAfter' in data['resource']:\n",
    "            named_after = data['resource']['isNamedAfter'][0]\n",
    "            return named_after\n",
    "        else:\n",
    "            named_after = \"no_named_after\"\n",
    "            return named_after\n",
    "    else:\n",
    "        named_after = \"ERROR\"\n",
    "        return named_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5befc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion zur Abfrage des Namens eines Ortes im Gazetteer\n",
    "def get_gaz_title(gaz_id):\n",
    "    gaz_id = gaz_id.split(\"/\")[-1]\n",
    "    url = f\"https://gazetteer.dainst.org/doc/{gaz_id}.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'prefName' in data:\n",
    "            title = data['prefName']['title']\n",
    "            return title\n",
    "        else:\n",
    "            title = \"ERROR_no_title!!!\"\n",
    "            return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b21f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Loop\n",
    "\n",
    "#ids to test the loop\n",
    "#chronoids = ['oUj62ZmY8g8U','bPXYskijLKfh','iHHsmCseJynu']\n",
    "\n",
    "processed_chrono_ids = []\n",
    "result = []\n",
    "names = []\n",
    "gaz_titles = []\n",
    "x = 0\n",
    "\n",
    "for chrono_id in chronoids:\n",
    "    x += 1\n",
    "    print(f\"processing {chrono_id}, nr. {x} of {len(chronoids)}\")\n",
    "    processed_chrono_ids.append(chrono_id)\n",
    "    name = get_chrono_name(chrono_id)\n",
    "    names.append(name)\n",
    "    core_area = get_chrono_core_area(chrono_id)\n",
    "    region = get_chrono_region(chrono_id)\n",
    "    named_after = get_chrono_named_after(chrono_id)\n",
    "    if core_area != \"no_core_area\":\n",
    "        gaz_title = get_gaz_title(core_area)\n",
    "        gaz_titles.append(gaz_title)\n",
    "        result.append(core_area)\n",
    "    elif region != \"no_region\":\n",
    "        gaz_title = get_gaz_title(region)\n",
    "        gaz_titles.append(gaz_title)\n",
    "        result.append(region)\n",
    "    elif named_after != \"no_named_after\":\n",
    "        gaz_title = get_gaz_title(named_after)\n",
    "        gaz_titles.append(gaz_title)\n",
    "        result.append(named_after)\n",
    "    else:\n",
    "        result.append(\"no_localization\")\n",
    "        gaz_titles.append(\"no_gaz_title\")\n",
    "    time.sleep(1)  # Sleep for 1 second to avoid overloading the API\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "df_results = pd.DataFrame({\n",
    "    'ChonoID': processed_chrono_ids,\n",
    "    'PeriodName': names,\n",
    "    'Localization': gaz_titles,\n",
    "    'GazetteerID': result\n",
    "})\n",
    "\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to Excel\n",
    "df_results.to_excel(\"chronontology_gazetteer_mapping.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5955e6f0",
   "metadata": {},
   "source": [
    "Um nur einzigartige Ortsbezeichnungen zu erhalten, kann der folgende Code auf die zuvor exportierte Tabelle angewendet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1615243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get unique Gazetteer IDs with place names\n",
    "df_gazetteer_mapping = pd.read_excel(\"chronontology_gazetteer_mapping.xlsx\", usecols=[\"GazetteerID\"])\n",
    "unique_gazetteer_ids = df_gazetteer_mapping['GazetteerID'].unique()\n",
    "\n",
    "placenames = []\n",
    "\n",
    "for gaz_id in unique_gazetteer_ids:\n",
    "    gaz_id = gaz_id.split(\"/\")[-1]\n",
    "    url = f\"https://gazetteer.dainst.org/doc/{gaz_id}.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'prefName' in data:\n",
    "            title = data['prefName']['title']\n",
    "            placenames.append((title))\n",
    "            print(f\"{gaz_id}: {title}\")\n",
    "        else:\n",
    "            print(f\"{gaz_id}: ERROR_no_title!!!\")\n",
    "            title = \"ERROR_no_title!!!\"\n",
    "            placenames.append((title))\n",
    "    else:\n",
    "        print(f\"{gaz_id}: ERROR fetching data\")\n",
    "        title = \"ERROR fetching data\"\n",
    "        placenames.append((title))\n",
    "\n",
    "# Create a DataFrame with the unique Gazetteer IDs and their place names\n",
    "df_placenames = pd.DataFrame({\n",
    "    'GazetteerID': unique_gazetteer_ids,\n",
    "    'PlaceName': placenames\n",
    "})\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "df_placenames.to_excel(\"unique_gazetteer_placenames.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd82d9",
   "metadata": {},
   "source": [
    "Entwickelt von Lukas Lammers im Projekt FAIR.rdm, teil des DFG-geförderten SPP 2143 \"Entangled Africa\".\n",
    "\n",
    "Mit Unterstützung von GitHub Copilot (KI-Assistent) bei der Code-Entwicklung und -Optimierung.\n",
    "\n",
    "Version 1.1, 30.07.2025\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
